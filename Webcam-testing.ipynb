{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5cde44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b9b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "from keras.models import load_model\n",
    "model = load_model('ASL landmarks using Dense v2.h5')\n",
    "# model = load_model('ASL-lm.h5')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43baf7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic  # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils  # Drawing utilities\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "mp_model = mp_hands.Hands(\n",
    "    static_image_mode=True,  # static images\n",
    "    max_num_hands=1,  # max 1 hands detection\n",
    "    min_detection_confidence=0.5)  # detection confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dcb9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_720p():\n",
    "    cap.set(3, 1280)\n",
    "    cap.set(4, 720)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1fe6642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    # COLOR CONVERSION BGR 2 RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e2f9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks,\n",
    "                              mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                              mp_drawing_styles.get_default_hand_connections_style()\n",
    "                            #   mp_drawing.DrawingSpec(\n",
    "                            #       color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                            #   mp_drawing.DrawingSpec(\n",
    "                            #       color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "    # Draw right hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks,\n",
    "                              mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                              mp_drawing_styles.get_default_hand_connections_style()\n",
    "                            #   mp_drawing.DrawingSpec(\n",
    "                            #       color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                            #   mp_drawing.DrawingSpec(\n",
    "                            #       color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe72e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_border(image, results):\n",
    "    h, w, c = image.shape\n",
    "    if results.left_hand_landmarks:\n",
    "        hand_landmarks = [results.left_hand_landmarks]\n",
    "    elif results.right_hand_landmarks:\n",
    "        hand_landmarks = [results.right_hand_landmarks]\n",
    "    else:\n",
    "        hand_landmarks = False\n",
    "\n",
    "    x_max = 0\n",
    "    y_max = 0\n",
    "    x_min = w\n",
    "    y_min = h\n",
    "\n",
    "    if hand_landmarks:\n",
    "        for handLMs in hand_landmarks:\n",
    "            for lm in handLMs.landmark:\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                if x > x_max:\n",
    "                    x_max = x\n",
    "                if x < x_min:\n",
    "                    x_min = x\n",
    "                if y > y_max:\n",
    "                    y_max = y\n",
    "                if y < y_min:\n",
    "                    y_min = y\n",
    "            cv2.rectangle(image, (x_min, y_min),\n",
    "                          (x_max, y_max), (255, 0, 105), 2)\n",
    "    return x_min, x_max, y_min, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf9abb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    if results.left_hand_landmarks != None:\n",
    "        x = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten(\n",
    "        ) if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    elif results.right_hand_landmarks != None:\n",
    "        x = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten(\n",
    "        ) if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94af677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image(image, x_min, x_max, y_min, y_max):\n",
    "    height, width, color = image.shape\n",
    "    if (x_max - x_min >= y_max - y_min):\n",
    "        h = x_max - x_min\n",
    "        y_min = y_min - 25\n",
    "        y_max = y_min + h\n",
    "    else:\n",
    "        h = y_max - y_min\n",
    "        x_min = x_min - 25\n",
    "        x_max = x_min + h\n",
    "\n",
    "    y_min = y_min - 25\n",
    "    y_max = y_max + 25\n",
    "    x_min = x_min - 25\n",
    "    x_max = x_max + 25\n",
    "    return image[y_min:y_max, x_min:x_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f27c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_image(img):\n",
    "    img_size = 80\n",
    "    minValue = 70\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 2)\n",
    "    th3 = cv2.adaptiveThreshold(\n",
    "        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    ret, res = cv2.threshold(\n",
    "        th3, minValue, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    resized = np.int_(cv2.resize(res, (img_size, img_size)))\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e490a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_keypoints(keypoints):\n",
    "    x = keypoints[0]*200\n",
    "    y = keypoints[1]*200\n",
    "    z = keypoints[2]*100\n",
    "    for j in range(63):\n",
    "        if j % 3 == 0:\n",
    "            keypoints[j] = keypoints[j]*200 - x\n",
    "        elif j % 3 == 1:\n",
    "            keypoints[j] = keypoints[j]*200 - y\n",
    "        else:\n",
    "            keypoints[j] = keypoints[j]*100 - z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0d0d28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "C\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "letterpred = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "              'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
    "              'W', 'X', 'Y', 'Z', 'del', 'space']\n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.8, min_tracking_confidence=0.8) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Change resolution\n",
    "        # make_720p()\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        k = cv2.waitKey(1)\n",
    "        if k % 256 == 27:\n",
    "            # ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "        # Make detections of hand\n",
    "        # image, results = mediapipe_detection(cv2.flip(frame, 1), holistic)\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        if results.left_hand_landmarks == None and results.right_hand_landmarks == None:\n",
    "            index = 'Nothing'\n",
    "        else:\n",
    "            # Draw a box around hand\n",
    "            x_min, x_max, y_min, y_max = draw_border(image, results)\n",
    "\n",
    "            # Draw landmarks\n",
    "            draw_styled_landmarks(image, results)\n",
    "\n",
    "            # Cropping Image\n",
    "            image_crop = extract_image(frame, x_min, x_max, y_min, y_max)\n",
    "\n",
    "            if k % 256 == 32:\n",
    "                # Extract keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                keypoints = keypoints.reshape(-1, 63)\n",
    "\n",
    "                # Make prediction\n",
    "                prediction = np.argmax(model.predict(keypoints)[0])\n",
    "                index = letterpred[prediction]\n",
    "                print(index)\n",
    "\n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3196968d684371006099b3d55edeef8ed90365227a30deaef86e5d4aa8519be0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
